1, VQA: Visual Question Answering:
  Paper contributions:  a new data set called VQA
                        a baseline model for answering questions (LSTM Q+I with 54.06%)
  Thinkings:  classifications for questions and treat them separetely
              For our models, we may can analyze if a question is related to audio or mid frame?
              
2, Recursive Visual Attention in Visual Dialog
  Pape contributions:   RvA algorithms to do visual dialog task on VisDial dataset.
                        RvA helps to resolveco-reference problem in the question. (ex. The pronoun and noun referring same entity)
                        RvA uses a infer module to decide if dialog history is needed
                        If DH is needed, there is a att and RvA module to compute the paired attention. The modules will recusivesly go back through DH to find the noun referred by the pronoun in the question
  Thinkings:  Same techniques can be applied to AVSAD dataset
              In addition to finding the referred noun in dialog history, we may can do sth similar with the video?

3, Image-Question-Answer Synergistic Network for Visual Dialog
  Paper contributions:  It improves performance of baseline system on dataset Visual Dialog v1.0
                        There are two stages for the models.
                        All candidate answers are scored in the primary stage, and some selected answers are re-scored in the
synergistic stage.
 
 4, Two can play this Game: Visual Dialog with Discriminative Question Generation
    http://openaccess.thecvf.com/content_cvpr_2018/papers/Jain_Two_Can_Play_CVPR_2018_paper.pdf
    Paper contributions: 
